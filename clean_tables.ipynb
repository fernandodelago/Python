{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91ce1540-7ef3-4e0a-8d87-2bb3052f54fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Fleet dashboard data pipeline\n",
    "\n",
    "In this notebook we display a compendium of functionalities through which necessary for the visualization tables are created from a set of 3 raw data sources.\n",
    "The structure is straightforward to follow, there are a set of auxiliary functionalities in the beginning leading which the data is read from an Azure SQL DB, it is processed leveraging the previous functionalities and later dumped into a blob storage container as csv's\n",
    "\n",
    "Throughout the notebook, references to what each and every table created is used for. Nonehteless, for a more exhaustive overview, please refer to the Fleet MvP documentation in which everything is in a full breath of detail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0092d954-ec14-44d5-9e82-2e44c9daa7ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##%sh pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42aab8b1-6627-4a07-8ba4-53ef535778ff",
     "showTitle": true,
     "title": "Define credentials to access the Azure SQL server"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"jdbcHostname\", \"\")\n",
    "jdbcHostname = dbutils.secrets.get(scope = \"mdugs-scope\", key = \"mdugs-sqlserver-hostname\") or dbutils.widgets.get(\"jdbcHostname\")\n",
    "\n",
    "dbutils.widgets.text(\"jdbcDatabase\", \"\")\n",
    "jdbcDatabase = dbutils.secrets.get(scope = \"mdugs-scope\", key = \"mdugs-sqlserver-database-datahub\") or dbutils.widgets.get(\"jdbcDatabase\")\n",
    "\n",
    "dbutils.widgets.text(\"jdbcPort\", \"\")\n",
    "jdbcPort = dbutils.secrets.get(scope = \"mdugs-scope\", key = \"mdugs-sqlserver-port\") or dbutils.widgets.get(\"jdbcPort\")\n",
    "\n",
    "dbutils.widgets.text(\"jdbcUser\", \"\")\n",
    "jdbcUser = dbutils.secrets.get(scope = \"mdugs-scope\", key = \"mdugs-sqlserver-user\") or dbutils.widgets.get(\"jdbcUser\")\n",
    "\n",
    "dbutils.widgets.text(\"jdbcPassword\", \"\")\n",
    "jdbcPassword = dbutils.secrets.get(scope = \"mdugs-scope\", key = \"mdugs-sqlserver-pass\") or dbutils.widgets.get(\"jdbcPassword\")\n",
    "\n",
    "properties = { \"user\": jdbcUser, \"password\": jdbcPassword, \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"}\n",
    "\n",
    "url = \"jdbc:sqlserver://{0}:{1};database={2}\".format(jdbcHostname, jdbcPort, jdbcDatabase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fca88d4-4178-4405-adbd-6bc6cd5a01ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storageName = dbutils.secrets.get(scope = \"mdugs-scope\", key = \"mdugs-storage-name\")\n",
    "storageKey = dbutils.secrets.get(scope = \"mdugs-scope\", key = \"mdugs-storage-config2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b2ab1d6-2f82-4249-9bf2-6523e6d6fd8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%sh pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03c17273-6f13-4c4f-8361-c66d36b05f96",
     "showTitle": true,
     "title": "Load necessary libraries"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## Added \n",
    "from azure.storage.blob import ContainerClient\n",
    "##\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from io import StringIO\n",
    "import io\n",
    "import numpy as np\n",
    "from pyspark.sql import *\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d17c7187-3af7-4a41-b45b-7f2c0ed6f0ed",
     "showTitle": true,
     "title": "Auxiliary functions to read / write to blob storage"
    }
   },
   "outputs": [],
   "source": [
    "def save_in_blob(df, file_name):\n",
    "  connectStr = \"DefaultEndpointsProtocol=https;AccountName={0};AccountKey={1};EndpointSuffix=core.windows.net\".format(storageName,storageKey)\n",
    "  containerName = \"scfrota\"\n",
    "  containerClient = ContainerClient.from_connection_string(conn_str=connectStr, container_name=containerName)\n",
    "\n",
    "  output = df.to_csv(index = False, encoding = \"utf-8\", sep = ';', decimal = ',')\n",
    "  output_blob_name = file_name + \".csv\"\n",
    "\n",
    "  try:\n",
    "    containerClient.upload_blob(name = output_blob_name, data = output)  \n",
    "  except:  \n",
    "    # if file already exists\n",
    "    containerClient.delete_blob(blob=output_blob_name)\n",
    "    containerClient.upload_blob(name = output_blob_name, data = output)    \n",
    "  return \"SAVED!\"\n",
    "\n",
    "\n",
    "def read_from_blob(file_name): \n",
    "  connectStr = \"DefaultEndpointsProtocol=https;AccountName={0};AccountKey={1};EndpointSuffix=core.windows.net\".format(storageName,storageKey)\n",
    "  containerName = \"scfrota\"\n",
    "  containerClient = ContainerClient.from_connection_string(conn_str=connectStr, container_name=containerName)\n",
    "  \n",
    "  try:  \n",
    "    file_str = containerClient.download_blob(file_name).readall().decode(\"utf-8\")\n",
    "  except:\n",
    "    return \"File does not exist.\"\n",
    "  df = pd.read_csv(StringIO(file_str), sep = ';', decimal = ',', encoding = 'utf-8')\n",
    "  return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff9c4c78-5359-44f7-9b05-d2b27c614cb5",
     "showTitle": true,
     "title": "Auxiliary functions to clean the Master tables"
    }
   },
   "outputs": [],
   "source": [
    "def add_trimester(x):\n",
    "  ''' Given a datetime object, returns the term in the desirable format for the dashboard display '''\n",
    "  if (x.month <= 3): return '1T'\n",
    "  if (x.month <= 6): return '2T'\n",
    "  if (x.month <= 9): return '3T'\n",
    "  return '4T'\n",
    "\n",
    "def moment_of_day(x):\n",
    "  if (x < '06'): return '4. Noite'\n",
    "  if (x > '19'): return '4. Noite'\n",
    "  if (x < '11'): return '1. Manhã'\n",
    "  if (x < '15'): return '2. Meio dia'\n",
    "  return '3. Tarde'\n",
    "\n",
    "def bins_kms(x):\n",
    "  if (x < 50000): return '1. <50k'\n",
    "  if (x < 100000): return '2. 50-100k'\n",
    "  if (x < 150000): return '3. 100-150k'\n",
    "  if (x < 200000): return '4. 150-200k'\n",
    "  if (x < 250000): return '5. 200-250k'\n",
    "  if (x < 300000): return '6. 250-300k'\n",
    "  if (x >= 300000): return '7. >300k'\n",
    "  return '1. <50k'\n",
    "\n",
    "def bins_years(x):\n",
    "  if (x <= 2): return '1. <2 yr'\n",
    "  if (x <= 4): return '2. 2-4 yr'\n",
    "  if (x <= 6): return '3. 4-6 yr'\n",
    "  if (x <= 8): return '4. 6-8 yr'\n",
    "  if (x <= 10): return '5. 8-10 yr'\n",
    "  if (x > 10): return '6. >10yr'\n",
    "  return '1. <2 yr'\n",
    "\n",
    "def days_bins(x):\n",
    "  if (x < 30): return '01. <30 dias'\n",
    "  if (x < 60): return '02. 30-60 dias'\n",
    "  if (x < 90): return '03. 60-90 dias'\n",
    "  if (x < 120): return '04. 90-120 dias'\n",
    "  if (x < 150): return '05. 120-150 dias'\n",
    "  if (x < 180): return '06. 150-180 dias'\n",
    "  if (x < 210): return '07. 180-210 dias'\n",
    "  if (x < 240): return '08. 210-240 dias'\n",
    "  if (x < 270): return '09. 240-270 dias'\n",
    "  if (x < 300): return '10. 270-300 dias'\n",
    "  if (x < 330): return '11. 300-330 dias'\n",
    "  if (x < 360): return '12. 330-360 dias'\n",
    "  if (x >= 360): return '13. >360 dias'\n",
    "  return '13. >360 dias'\n",
    "\n",
    "def bins_kms2(x):\n",
    "  if (x < 25000): return '01. <25k'\n",
    "  if (x < 50000): return '02. 25-50k'\n",
    "  if (x < 75000): return '03. 50-75k'\n",
    "  if (x < 100000): return '04. 75-100k'\n",
    "  if (x < 125000): return '05. 100-125k'\n",
    "  if (x < 150000): return '06. 125-150k'\n",
    "  if (x < 175000): return '07. 150-175k'\n",
    "  if (x < 200000): return '08. 175-200k'\n",
    "  if (x < 225000): return '09. 200-225k'\n",
    "  if (x < 250000): return '10. 225-250k'\n",
    "  if (x >= 250000): return '11. >250k'\n",
    "  return '01. <25k'\n",
    "\n",
    "def bins_years2(x):\n",
    "  if (x <= 2): return '01. <2 yr'\n",
    "  if (x <= 4): return '02. 2-4 yr'\n",
    "  if (x <= 6): return '03. 4-6 yr'\n",
    "  if (x <= 8): return '04. 6-8 yr'\n",
    "  if (x <= 10): return '05. 8-10 yr'\n",
    "  if (x <= 12): return '06. 10-12 yr'\n",
    "  if (x <= 14): return '07. 12-14 yr'\n",
    "  if (x > 14): return '08. >14 yr'\n",
    "  return '01. <1 yr'\n",
    "\n",
    "def bins_repairs2(x):\n",
    "  if (x <= 20): return '1. <20'\n",
    "  if (x <= 40): return '2. 20-40'\n",
    "  if (x <= 60): return '3. 40-60'\n",
    "  if (x <= 80): return '4. 60-80'\n",
    "  if (x <= 100): return '5. 80-100'\n",
    "  if (x <= 120): return '6. 100-120'\n",
    "  if (x <= 140): return '7. 120-1400'\n",
    "  if (x > 140): return '8. >140'\n",
    "  return '1. <20'\n",
    "\n",
    "def bins_kms3(x):\n",
    "  if (x < 1000): return '1. <1k'\n",
    "  if (x < 2500): return '2. 1-2.5k'\n",
    "  if (x < 5000): return '3. 2.5-5k'\n",
    "  if (x < 7500): return '4. 5-7.5k'\n",
    "  if (x < 10000): return '5. 7.5-10k'\n",
    "  if (x < 15000): return '6. 10-15k'\n",
    "  if (x < 20000): return '7. 15-20k'\n",
    "  if (x >= 20000): return '8. >20k'\n",
    "  return '4. 5-7.5k'\n",
    "  \n",
    "def bins_repairs3(x):\n",
    "  if (x == 0): return '0'\n",
    "  if (x == 1): return '1'\n",
    "  if (x  == 2): return '2'\n",
    "  if (x == 3): return '3'\n",
    "  if (x == 4): return '4'\n",
    "  if (x == 5): return '5'\n",
    "  if (x == 6): return '6'\n",
    "  if (x >6): return 'Mais de 6'\n",
    "  return '0'\n",
    "\n",
    "\n",
    "def clean_movimentos(data):\n",
    "    # Fill null values\n",
    "    NAtoUnknownMask = ['mov_movement_type','mov_plate','mov_category_of_vehicle','mov_movement_description',\n",
    "                       'mov_owner_company','mov_fleet_manager','mov_status','mov_odometer_unit','mov_supplier','mov_operation',\n",
    "                       'mov_sub_operation','mov_exit','mov_currency', 'mov_accident_location', 'mov_cost_center']\n",
    "    \n",
    "    data.loc[:, NAtoUnknownMask] = data.loc[:, NAtoUnknownMask].fillna(\"UNKNOWN\")\n",
    "    \n",
    "    # Specify the country for a better location in the dashboard maps\n",
    "    data['mov_accident_location'] = data['mov_accident_location'].astype(str)+', Portugal'\n",
    "    data['mov_exit'] = data['mov_exit'].astype(str)+', Portugal'\n",
    "    \n",
    "    # Clean the owner company variable \n",
    "    dict_owner_company = dict(zip(data.mov_owner_company.unique(), data.mov_owner_company.unique()))\n",
    "    dict_owner_company['EDP DISTRIBUIÇAO'] = 'EDP DISTRIBUIÇÃO'\n",
    "    dict_owner_company['EDP GESTAO DA PRODUÇAO DE ENERGIA'] = 'EDP GESTÃO DA PRODUÇÃO DE ENERGIA'\n",
    "    dict_owner_company['EDP SOLUÇOES COMERCIAIS'] = 'EDP SOLUÇÕES COMERCIAIS'\n",
    "    dict_owner_company['FUNDAÇAO EDP'] = 'FUNDAÇÃO EDP'\n",
    "    dict_owner_company['\"EDP INTERNACIONAL, SA\"'] = 'EDP INTERNACIONAL, SA'\n",
    "    dict_owner_company['EDP INOVAÇAO'] = 'EDP INOVAÇÃO'\n",
    "    dict_owner_company['SAVIDA'] = 'SÃVIDA'\n",
    "    data['mov_owner_company'] = data['mov_owner_company'].map(dict_owner_company)\n",
    "\n",
    "    # Consider as accident every movement with a Accident ID associated\n",
    "    data['mov_accident'] = 'Yes'\n",
    "    data.loc[data['mov_accident_id'].isnull(), 'mov_accident'] = 'No'\n",
    "    data.loc[data['mov_accident_id'] == '', 'mov_accident'] = 'No'\n",
    "\n",
    "    # Scheduled: changed to Yes/No\n",
    "    # Operations related to accidents appear as scheduled, marking them\n",
    "    # as no scheduled because the cause was an accident\n",
    "    scheduledMask = (~data['mov_scheduled'].isnull()) & (data['mov_scheduled']!='') & (data['mov_accident'] == 'No')\n",
    "    data.loc[~scheduledMask, 'mov_scheduled'] = 'No'\n",
    "    data.loc[scheduledMask, 'mov_scheduled'] = 'Yes'\n",
    "\n",
    "    # Creating new feature to split movements by type\n",
    "    data[\"mov_movement_category\"] = \"DIRECT_COST_USAGE\"\n",
    "    maskType = ((data[\"mov_movement_type\"] == \"SERVIÇOS\") | \n",
    "                (data[\"mov_movement_type\"] == \"REQUISIÇÃO OFICINA\") | \n",
    "                (data[\"mov_movement_type\"] == \"TIRES\") | \n",
    "                (data[\"mov_movement_type\"] == \"IPO\")) & (data[\"mov_accident\"] == \"No\")\n",
    "\n",
    "    data.loc[maskType, \"mov_movement_category\"] = \"MAINTENANCE\"\n",
    "    data.loc[maskType, \"mov_movement_type\"] = \"NO SCHEDULED\"\n",
    "    maskScheduled = data[\"mov_scheduled\"] == \"Yes\"\n",
    "    data.loc[maskScheduled, \"mov_movement_type\"] = \"SCHEDULED\"\n",
    "    maskSinistro = data[\"mov_accident\"] == \"Yes\"\n",
    "    data.loc[maskSinistro, \"mov_movement_type\"] = \"SINISTRO\"\n",
    "    maskTires = ((data[\"mov_sub_operation\"] == \"ECVAL\") | (data[\"mov_sub_operation\"] == \"ECVAL\") | \n",
    "                 (data[\"mov_sub_operation\"] == \"PNE01\") | (data[\"mov_sub_operation\"] == \"PNE02\") | \n",
    "                 (data[\"mov_sub_operation\"] == \"PNE02\") | (data[\"mov_sub_operation\"] == \"PNE98\"))\n",
    "    data.loc[maskTires, \"mov_movement_type\"] = \"TIRES\"\n",
    "    data.drop(\"mov_accident_id\", axis = 1, inplace = True)\n",
    "    \n",
    "    # Treat movement date as a date\n",
    "    data.mov_movement_date = pd.to_datetime(data.mov_movement_date)\n",
    "    data = data[data.mov_movement_date >= pd.Timestamp('2018-01-01')]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def clean_viaturas(data):\n",
    "    # Fill null values\n",
    "    data.loc[:, data.columns[data.dtypes == \"object\"]] = data.loc[:, data.columns[data.dtypes == \"object\"]].fillna(\"UNKNOWN\")\n",
    "    data.loc[:, data.columns[data.dtypes == \"int64\"]] = data.loc[:, data.columns[data.dtypes == \"int64\"]].fillna(-1)\n",
    "    data.loc[:, data.columns[data.dtypes == \"float64\"]] = data.loc[:, data.columns[data.dtypes == \"float64\"]].fillna(-1)\n",
    "    \n",
    "    # Add owner company based on code of empresa proprietaria\n",
    "    mapping_owner_company = {'G1000': 'EDP ENERGIAS DE PORTUGAL', 'G2000': 'EDP GESTÃO DA PRODUÇÃO DE ENERGIA','G2130': 'TERGEN', 'G2610': 'EDP GESTÃO DA PRODUÇÃO DE ENERGIA',\n",
    "                             'G2800': 'EDP DISTRIBUIÇÃO','G2820': 'EDP SERVIÇO UNIVERSAL','G2822': 'EDP DISTRIBUIÇÃO','G2900': 'EDP COMERCIAL','G3255': 'EDPR PT - PROMOÇÃO E OPERAÇÃO S A',\n",
    "                             'G4000': 'REN GÁS DISTRIBUIÇAO SGPS, S.A.','G4170': 'REN PORTGÁS DISTRIBUIÇAO, S.A.','G4250': 'EDP VALOR GEST.INT.SERV.','G4260': 'EDP GÁS SERVIÇO UNIVERSAL',\n",
    "                             'G6310': 'EDP IMOBILIÁRIA E PARTIC.','G6330': 'LABELEC','G6340': 'SÃVIDA','G6370': 'EDP INTERNACIONAL, SA','G6390': 'EDP VALOR GEST.INT.SERV.',\n",
    "                             'G6890': 'EDP SOLUÇÕES COMERCIAIS','G6900': 'EDP ESTUDOS E CONSULTORIA','G6940': 'EDP ENERGIAS DE PORTUGAL','G6990': 'FUNDAÇÃO EDP','G6150': 'Home Energy II',\n",
    "                             'G2110': 'OEM SERVIÇOS'}\n",
    "    data['via_company'] = data.via_emp_prop.map(mapping_owner_company)\n",
    "    \n",
    "    # Homogenize the fuel variable\n",
    "    mapping_fuel = {'GASÓLEO': 'Combustão', 'ENERGIA ELÉCTRICA': 'Elétricos e Plug-Ins', 'PLUG-IN GASOLINA': 'Elétricos e Plug-Ins',\n",
    "                    'GASOLINA': 'Combustão', 'SEM COMBUSTÍVEL': 'Sem Combustivel', \n",
    "                    'HÍBRIDO GASOLINA': 'Híbridos', 'GASOLINA/GAS NATURAL': 'Combustão', 'HÍBRIDO GASÓLEO': 'Híbridos', \n",
    "                    'GÁS PROPANO GARRAFA': 'Combustão', 'PLUG-IN GASÓLEO': 'Elétricos e Plug-Ins'}\n",
    "    data['via_fuel'] = data['via_fuel'].map(mapping_fuel)\n",
    "    \n",
    "    # Homogenize the attribution variable\n",
    "    mapping_attribution = {'SERVIÇO':  'Viaturas de Serviço', 'VUP': 'VUPs', 'SERVIÇO PIQUETE': 'Viaturas de Serviço', 'POOL GERAL':  'POOL GERAL', 'VUP/CA': 'VUPs',\n",
    "                           'POOL VUP/VS': 'POOL VUP/VS','POOL CA': 'POOL CA'}\n",
    "    data['via_attribution'] = data['via_attribution'].map(mapping_attribution)\n",
    "    \n",
    "    # Add snapshot variables\n",
    "    data['snapshot_date'] = pd.to_datetime(data['via_year'].astype(str)+'-'+data['via_month'].astype(str)) + pd.offsets.MonthEnd(0)\n",
    "    data['trimester'] = data['snapshot_date'].apply(lambda x: add_trimester(x))\n",
    "    data['is_last_snapshot'] = data['snapshot_date'] == data['snapshot_date'].max()\n",
    "    \n",
    "    # Add viatura age based on today's date\n",
    "    data.via_date_of_registration = pd.to_datetime(data.via_date_of_registration)\n",
    "    data.via_modified = pd.to_datetime(data.via_modified)\n",
    "    data['years_old'] = (pd.Timestamp.today() - data.via_date_of_registration).apply(lambda x: (x.days/365))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d3b0d50-3b32-4236-ae3e-d1a56c890853",
     "showTitle": true,
     "title": "Auxiliary functions to read and load the Master tables"
    }
   },
   "outputs": [],
   "source": [
    "def load_viaturas():\n",
    "  print('Loading viaturas Master table :::', time.ctime())\n",
    "  # READ DATA FROM SQL DB\n",
    "  pushdown_query_viatura = \"(select * from [dbo].[dim_viatura]) emp_id\"\n",
    "  viaturas = spark.read.jdbc(url=url, table=pushdown_query_viatura, properties=properties).toPandas()\n",
    "  \n",
    "  # RENAME \n",
    "  config_viaturas = read_from_blob('/in/config/0_config_viaturas.csv')\n",
    "  viaturas = viaturas[config_viaturas.column]\n",
    "  viaturas = viaturas.astype(dict(zip(config_viaturas.column, config_viaturas.newtype)))\n",
    "  viaturas.columns = config_viaturas.new_name\n",
    "  \n",
    "  # CLEAN \n",
    "  viaturas = clean_viaturas(viaturas)\n",
    "  return viaturas\n",
    "\n",
    "\n",
    "def load_movimentos():\n",
    "  print('Loading movimentos Master table :::', time.ctime())\n",
    "  # READ DATA FROM SQL DB\n",
    "  pushdown_query_movimentos = \"(select * from [dbo].[fact_movimentos]) emp_id\"\n",
    "  movimentos = spark.read.jdbc(url=url, table=pushdown_query_movimentos, properties=properties).toPandas()\n",
    "  \n",
    "  # RENAME\n",
    "  config_movimentos = read_from_blob('/in/config/0_config_movimentos.csv')\n",
    "  movimentos = movimentos.astype(dict(zip(config_movimentos.column, config_movimentos.newtype)))\n",
    "  movimentos.columns = config_movimentos.new_name\n",
    "  \n",
    "  # CLEAN\n",
    "  movimentos_clean = clean_movimentos(movimentos)\n",
    "  return movimentos_clean\n",
    "\n",
    "def load_cadastro():\n",
    "  print('Loading Cadastro Master table :::', time.ctime())\n",
    "  # READ DATA FROM SQL DB\n",
    "  pushdown_query_rh = \"(select * from [dbo].[dim_rh]) emp_id\"\n",
    "  rh = spark.read.jdbc(url=url, table=pushdown_query_rh, properties=properties).toPandas()\n",
    "  \n",
    "  # RENAME\n",
    "  config_cadastro = read_from_blob('/in/config/0_config_cadastro.csv')\n",
    "  rh = rh[config_cadastro.column]\n",
    "  rh = rh.astype(dict(zip(config_cadastro.column, config_cadastro.newtype)))\n",
    "  rh.columns = config_cadastro.new_name\n",
    "\n",
    "  return rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25e93d3e-e5d3-4165-90e5-276b5b912019",
     "showTitle": true,
     "title": "0. Filtering table"
    }
   },
   "outputs": [],
   "source": [
    "def filters_table(clean_viaturas):\n",
    "  '''Auxiliary function to create the table used for the right hand side slicers in PowerBI\n",
    "  Returns a table with licence plate as a unique key and all the observed combinations of the desired filters: status, category, fuel,\n",
    "  attribution, cost center, company, classification, city and brand'''\n",
    "  \n",
    "  filters = clean_viaturas.sort_values('snapshot_date', ascending = False).drop_duplicates('via_plate')[['via_plate','via_status', 'via_category', \n",
    "                                                                                                         'via_fuel', 'via_attribution', 'via_cost_center', \n",
    "                                                                                                         'via_company', 'via_classification', 'via_city', \n",
    "                                                                                                         'via_brand']].reset_index(drop = True)\n",
    "  return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b4b3244-f52c-41e6-9093-cb04ca8523f9",
     "showTitle": true,
     "title": "1. Fleet-Status"
    }
   },
   "outputs": [],
   "source": [
    "def fleet_status_table(clean_movimentos, clean_viaturas, cadastro):\n",
    "    print('1. Creating Fleet-Status table :::', time.ctime())\n",
    "    \n",
    "    # Select only operative vehicles\n",
    "    fleet_status = clean_viaturas[clean_viaturas.via_status.isin(['IMOB. POR ACIDENTE','OPERACIONAL'])]\n",
    "\n",
    "    # Add age and KM bucket\n",
    "    fleet_status['km_bucket'] = fleet_status.via_total_kms.apply(lambda x: bins_kms(x))\n",
    "    fleet_status['age_bucket'] = (fleet_status.years_old).apply(lambda x: bins_years(x))\n",
    "    \n",
    "    # Add electric variables\n",
    "    fleet_status.loc[fleet_status.via_fuel == 'ENERGIA ELÉCTRICA', 'electric_km'] = fleet_status['via_total_kms']\n",
    "    fleet_status.loc[fleet_status.via_fuel != 'ENERGIA ELÉCTRICA', 'non_electric_km'] = fleet_status['via_total_kms']\n",
    "    fleet_status['electric_km'].fillna(0, inplace = True)\n",
    "    fleet_status['non_electric_km'].fillna(0, inplace = True)\n",
    "    fleet_status['is_electric'] = (fleet_status.via_fuel == 'Elétricos e Plug-Ins').astype(float)*100\n",
    "\n",
    "    # Add variables related to KM based on abastecimentos from movimentos\n",
    "    abastecimentos = clean_movimentos[clean_movimentos.mov_movement_type == 'ABASTECIMENTO']\n",
    "    fleet_status['number_abastecimentos'] = fleet_status.via_plate.map(abastecimentos.groupby('mov_plate').size()).fillna(0)\n",
    "    fleet_status['number_sch_maintenance'] = fleet_status.via_plate.map(clean_movimentos[clean_movimentos.mov_movement_type == 'SCHEDULED'].groupby('mov_plate').size()).fillna(0)\n",
    "    fleet_status['number_nosch_maintenance'] = fleet_status.via_plate.map(clean_movimentos[clean_movimentos.mov_movement_type == 'NO SCHEDULED'].groupby('mov_plate').size()).fillna(0)\n",
    "    fleet_status['number_tires'] = fleet_status.via_plate.map(clean_movimentos[clean_movimentos.mov_movement_type == 'TIRES'].groupby('mov_plate').size()).fillna(0)\n",
    "    fleet_status['number_tolls'] = fleet_status.via_plate.map(clean_movimentos[clean_movimentos.mov_movement_type == 'PORTAGEMS'].groupby('mov_plate').size()).fillna(0)\n",
    "\n",
    "    fleet_status['first_abastecimento'] = fleet_status.via_plate.map(abastecimentos.groupby('mov_plate').mov_movement_date.min()).fillna(pd.Timestamp('1900-01-01'))\n",
    "    fleet_status['last_abastecimento'] = fleet_status.via_plate.map(abastecimentos.groupby('mov_plate').mov_movement_date.max()).fillna(pd.Timestamp('1900-01-01'))\n",
    "    fleet_status['days_since_first_abastecimento'] = (fleet_status['last_abastecimento'] - fleet_status['first_abastecimento']).apply(lambda x: x.days).fillna(0)+1\n",
    "    fleet_status['liters_consumed'] = fleet_status.via_plate.map(abastecimentos.groupby('mov_plate').mov_quantity.sum()).fillna(0)\n",
    "    \n",
    "    \n",
    "    # Add number of collaborators by viatura variable and increase / decrease indicators\n",
    "    fleet_status['colabviatura'] = round(fleet_status[fleet_status.is_last_snapshot == True].shape[0] / \n",
    "                                          cadastro[(cadastro.cad_headcount == 'Sim') & (cadastro.cad_year == 2019) & (cadastro.cad_month == 9)].cad_colaborador_num.nunique(),2)\n",
    "    fleet_status['increasecolab'] = -0.01\n",
    "    \n",
    "    cars_one_year_before = fleet_status[fleet_status.snapshot_date == sorted(fleet_status.snapshot_date.unique())[-12]].via_plate.nunique()\n",
    "    fleet_status['increaseviaturas'] = round((fleet_status['is_last_snapshot'].sum()-cars_one_year_before) / cars_one_year_before,2)\n",
    "    \n",
    "    \n",
    "    # Select columns to stick with\n",
    "    fleet_status_cols = ['snapshot_date', 'is_last_snapshot', 'via_plate', 'km_bucket', 'age_bucket', 'via_total_kms',\n",
    "                         'electric_km', 'non_electric_km', 'via_co2_emissions', 'via_brand', 'via_city',\n",
    "                         'via_category', 'via_fuel', 'via_attribution', 'via_company', 'via_acquisition_value',\n",
    "                         'years_old', 'number_abastecimentos', 'first_abastecimento', 'last_abastecimento',\n",
    "                         'days_since_first_abastecimento', 'liters_consumed', 'is_electric',  'via_status', \n",
    "                         'number_sch_maintenance', 'number_nosch_maintenance', 'number_tires', 'number_tolls', 'via_cost_center', \n",
    "                         'trimester', 'colabviatura', 'increaseviaturas', 'increasecolab']\n",
    "    \n",
    "    fleet_status = fleet_status[fleet_status_cols]\n",
    "    \n",
    "    return fleet_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52e958bc-68f6-4bb1-b2cd-b2444f9a1b05",
     "showTitle": true,
     "title": "2. Fleet-Balances"
    }
   },
   "outputs": [],
   "source": [
    "def fleet_balances_table(clean_viaturas, clean_movimentos):\n",
    "  '''Auxiliary function that returns a table with all the viaturas per snapshot indicating if they were an transfer (entering or exiting) and furhtermore, \n",
    "  denoting whether it was internal or not'''\n",
    "\n",
    "  print('2. Creating Fleet-Balances table :::', time.ctime())\n",
    "\n",
    "  fleet_balances = clean_viaturas[['snapshot_date', 'via_plate', 'via_status','via_attribution',\n",
    "                                  'via_brand', 'via_city', 'via_company', 'via_category', 'via_fuel',\n",
    "                                  'via_date_of_registration', 'via_cost_center', 'trimester']].sort_values('snapshot_date')\n",
    "\n",
    "  fleet_balances['snapshot_plate'] = clean_viaturas['snapshot_date'].astype(str)+'_'+clean_viaturas['via_plate'].astype(str)\n",
    "  fleet_balances['is_last_period'] = (fleet_balances['snapshot_date'] >= pd.to_datetime(str(fleet_balances['snapshot_date'].max().year)+'-01')).astype(float)\n",
    "  fleet_balances['is_active'] = fleet_balances['snapshot_plate'].map(\n",
    "      fleet_balances.groupby('snapshot_plate').via_status.apply(lambda x: ('OPERACIONAL' in list(x)) or ('IMOB. POR ACIDENTE' in list(x))))\n",
    "\n",
    "  # Inclusion of the previous_active flag indicating whether a plate in a given snapshot was active in the past month\n",
    "  previous_state = dict()\n",
    "  for i in fleet_balances.snapshot_date.unique():\n",
    "      fleet_balances.loc[fleet_balances.snapshot_date == i, 'previous_active'] = fleet_balances.via_plate.map(previous_state)\n",
    "      previous_state = fleet_balances.loc[fleet_balances.snapshot_date == i].groupby('via_plate').is_active.max().fillna(0)\n",
    "  fleet_balances['previous_active'].fillna(False, inplace = True)\n",
    "\n",
    "  # Inclusion of flags to indicate if the combination of plate and snapshot changed to inactive or to active\n",
    "  fleet_balances['changed_inactive'] = ((fleet_balances['is_active'] == False) & (fleet_balances.previous_active == True)).astype(float)\n",
    "  fleet_balances.loc[fleet_balances.changed_inactive == 1,'changed_inactive'] = -1\n",
    "  fleet_balances['changed_active'] = ((fleet_balances['is_active'] == True) & (fleet_balances.previous_active == False)).astype(float)\n",
    "  fleet_balances.loc[fleet_balances.snapshot_date <= '2018-02-01', 'changed_active'] = 0\n",
    "  fleet_balances['abs_changed_inactive'] = abs(fleet_balances.changed_inactive)\n",
    "\n",
    "  # Add internal sale flag indicating whether the cange was made to the exterior or it was an internal movement\n",
    "  # We leverage the last date of observation for each car to determine the last selling date\n",
    "  fleet_balances['last_active_date'] = fleet_balances.via_plate.map(fleet_balances[fleet_balances.is_active].groupby('via_plate')['snapshot_date'].max())\n",
    "  fleet_balances['first_active_date'] = fleet_balances.via_plate.map(fleet_balances[fleet_balances.is_active].groupby('via_plate')['snapshot_date'].min())\n",
    "  fleet_balances['internal_sale'] = 0\n",
    "  fleet_balances.loc[(fleet_balances.changed_inactive != 0) & (fleet_balances.snapshot_date < fleet_balances.last_active_date ), 'internal_sale'] = 1\n",
    "  fleet_balances.loc[(fleet_balances.changed_active != 0) & (fleet_balances.snapshot_date > fleet_balances.first_active_date ), 'internal_sale'] = 1\n",
    "  fleet_balances = fleet_balances.drop_duplicates('snapshot_plate', keep = 'first')\n",
    "\n",
    "\n",
    "  # Add purchase details\n",
    "  fleet_balances['via_acquisition_value'] = -fleet_balances.via_plate.map(clean_viaturas.groupby('via_plate').via_acquisition_value.max())\n",
    "  fleet_balances['abs_via_acquisition_value'] = abs(fleet_balances['via_acquisition_value'])\n",
    "  fleet_balances['via_actual_selling_price'] = fleet_balances.via_plate.map(clean_viaturas.groupby('via_plate').via_actual_selling_price.max())\n",
    "\n",
    "  # Add KM and age bucket variables\n",
    "  fleet_balances['km'] = fleet_balances.via_plate.map(clean_viaturas.groupby('via_plate').via_total_kms.max())\n",
    "  fleet_balances['km_bucket'] = fleet_balances.km.apply(lambda x: bins_kms(x))\n",
    "\n",
    "  # Overwrite years old variable baesd on last active date instead of today's date\n",
    "  fleet_balances.loc[fleet_balances.last_active_date.notnull(),'years_old'] = (fleet_balances.last_active_date - fleet_balances.via_date_of_registration).dt.days / 365\n",
    "  fleet_balances['age_bucket'] = fleet_balances.years_old.apply(lambda x: bins_years(x))\n",
    "\n",
    "\n",
    "  # Select columns to stick with\n",
    "  fleet_balance_cols = ['snapshot_date','via_plate','via_status','via_attribution','via_brand','via_city','via_company','via_category','via_fuel','via_date_of_registration',\n",
    "                        'via_cost_center','trimester','snapshot_plate','is_last_period', 'is_active', 'previous_active','changed_inactive','changed_active',\n",
    "                        'abs_changed_inactive','last_active_date',\t'first_active_date',\t'internal_sale',\t'via_acquisition_value',\t'abs_via_acquisition_value',\n",
    "                        'via_actual_selling_price',\t'km',\t'km_bucket','years_old', 'age_bucket']\n",
    "  fleet_balances = fleet_balances[fleet_balance_cols]\n",
    "\n",
    "  # Rename certain fields for a portuguese visualization in PowerBI\n",
    "  fleet_balances.rename(columns = {'changed_inactive': 'Mudança pana não activo', 'changed_active': 'Mudança pana activo'}, inplace = True)\n",
    "\n",
    "  return fleet_balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f709e43c-774e-49a8-a3bc-893e625852cb",
     "showTitle": true,
     "title": "3. CAPEX"
    }
   },
   "outputs": [],
   "source": [
    "def capex_table(fleet_balances, clean_viaturas, clean_movimentos):\n",
    "  '''Auxiliary function that creates a table with the capital transfers due to entries and exits from the fleet. \n",
    "  It heavily relies on the fleet balances computed previously. Two types of transfers are concatenated in the same format to create the final capex table, acquisitions and dismissals'''\n",
    "\n",
    "  print('3. Creating CAPEX table :::', time.ctime())\n",
    "\n",
    "  # Define acquisitions\n",
    "  acquisitions = fleet_balances[(fleet_balances['internal_sale'] == 0) & (fleet_balances['Mudança pana activo'] == 1)][['via_plate', 'snapshot_date']]\n",
    "  acquisitions.columns = ['via_plate', 'last_date']\n",
    "  acquisitions['first_date'] = acquisitions.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_date_of_registration)))\n",
    "  acquisitions['via_category'] = acquisitions.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_category)))\n",
    "  acquisitions['via_fuel'] = acquisitions.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_fuel)))\n",
    "  acquisitions['years_old'] = acquisitions.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.years_old)))\n",
    "  acquisitions['via_attribution'] = acquisitions.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_attribution)))\n",
    "  acquisitions['via_acquisition_value'] = -acquisitions.via_plate.map(clean_viaturas.groupby('via_plate').via_acquisition_value.max())\n",
    "  acquisitions['via_actual_selling_price'] = 0\n",
    "  acquisitions['km'] = acquisitions.via_plate.map(clean_viaturas.groupby('via_plate').via_total_kms.max())\n",
    "  acquisitions['below_250k'] = (acquisitions['km'] < 250000).astype(float)\n",
    "  acquisitions['below_8yrs'] = (acquisitions['years_old'] < 8).astype(float)\n",
    "  acquisitions['acquired'] = 1\n",
    "  acquisitions['sold'] = 0\n",
    "  acquisitions['status'] = 'BOUGHT'\n",
    "\n",
    "  # Define dismissals\n",
    "  dismissals = fleet_balances[(fleet_balances['internal_sale'] == 0) & (fleet_balances['Mudança pana não activo'] == -1)][['via_plate', 'snapshot_date']]\n",
    "  dismissals.columns = ['via_plate', 'last_date']\n",
    "  selling_statuses = ['ENTREGUE À LEILOEIRA', 'IDENTIFICADA PARA DO', 'IMOB. PARA VENDA', 'VENDIDA']\n",
    "  min_dates = clean_viaturas[clean_viaturas.via_status.isin(selling_statuses)].groupby('via_plate')['via_modified'].min()\n",
    "  max_dates = clean_viaturas[clean_viaturas.via_status.isin(selling_statuses)].groupby('via_plate')['via_modified'].max()\n",
    "  dismissals['first_date'] = dismissals.via_plate.map(min_dates)\n",
    "  dismissals['via_category'] = dismissals.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_category)))\n",
    "  dismissals['via_fuel'] = dismissals.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_fuel)))\n",
    "  dismissals['years_old'] = (dismissals['last_date'] - dismissals.via_plate.map(dict(zip(\n",
    "      clean_viaturas.via_plate,clean_viaturas.via_date_of_registration)))).apply(lambda x: (x.days/365))\n",
    "  dismissals['via_attribution'] = dismissals.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_attribution)))\n",
    "  dismissals['via_acquisition_value'] = 0\n",
    "  dismissals['via_actual_selling_price'] = dismissals.via_plate.map(clean_viaturas.groupby('via_plate').via_actual_selling_price.max())\n",
    "  dismissals['km'] = dismissals.via_plate.map(clean_viaturas.groupby('via_plate').via_total_kms.max())\n",
    "  dismissals['below_250k'] = (dismissals['km'] < 250000).astype(float)\n",
    "  dismissals['below_8yrs'] = (dismissals['years_old'] < 8).astype(float)\n",
    "  dismissals['acquired'] = 0\n",
    "  dismissals['sold'] = 1\n",
    "  dismissals['status'] = 'SOLD'\n",
    "\n",
    "  # Concatenate dismissals and acquisitions to get the full capex table\n",
    "  capex = pd.concat([acquisitions, dismissals]).reset_index(drop = True)\n",
    "  capex['abs_acquisition_value'] = abs(capex['via_acquisition_value'])\n",
    "  capex['cost_center'] = capex.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_cost_center))).astype(str)\n",
    "  capex['company'] = capex.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_company))).astype(str)\n",
    "  capex['is_last_period'] = (capex.last_date >= pd.to_datetime(str(capex.last_date.max().year)+'-01')).astype(float)\n",
    "  capex['trimester'] = capex['last_date'].apply(lambda x: add_trimester(x))\n",
    "\n",
    "\n",
    "  # Add age and km buckets for the visualizations\n",
    "  capex['km_bucket'] = capex.km.apply(lambda x: bins_kms(x))\n",
    "  capex['age_bucket'] = capex.years_old.apply(lambda x: bins_years(x))\n",
    "\n",
    "  # Select columns to stick with\n",
    "  capex_cols = ['via_plate',\t'last_date',\t'first_date',\t'via_category',\t'via_fuel',\t'years_old',\t'via_attribution',\t'via_acquisition_value',\t\n",
    "                'via_actual_selling_price',\t'km',\t'below_250k',\t'below_8yrs',\t'acquired',\t'sold',\t'status',\t'abs_acquisition_value',\t\n",
    "                'cost_center','company','is_last_period',\t'trimester',\t'km_bucket',\t'age_bucket']\n",
    "  capex = capex[capex_cols]\n",
    "\n",
    "  # Rename certain fields for the adequate portuguese visualization\n",
    "  capex.rename(columns = {'via_acquisition_value': 'Valor de aquisição', 'via_actual_selling_price': 'Valor de venda'}, inplace = True)\n",
    "\n",
    "  return capex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "785624e1-ba8e-4a42-bfc5-c70678f2c968",
     "showTitle": true,
     "title": "4. OPEX"
    }
   },
   "outputs": [],
   "source": [
    "def opex_table(clean_viaturas, clean_movimentos):\n",
    "    ''' Auxiliary function that returns the opex table. A table with the clean movements and additional indicators that is ready to be visualized in the dashboard '''\n",
    "  \n",
    "    print('4. Creating OPEX table :::', time.ctime())\n",
    "    \n",
    "    opex_breakdown = clean_movimentos[['mov_plate', 'mov_movement_date','mov_movement_time','mov_movement_type', 'mov_kms', \n",
    "                                       'mov_quantity', 'mov_total_net_price', 'mov_supplier', 'mov_owner_company',\n",
    "                                       'mov_movement_description', 'mov_accident_location', 'mov_exit','mov_cost_center', \n",
    "                                       'mov_category_of_vehicle', 'mov_status']]\n",
    "    \n",
    "    opex_breakdown['trimester'] = opex_breakdown['mov_movement_date'].apply(lambda x: add_trimester(x))\n",
    "    opex_breakdown['is_last_period'] = (opex_breakdown['mov_movement_date'] >= pd.to_datetime(str(opex_breakdown['mov_movement_date'].max().year)+'-01')).astype(float)\n",
    "    opex_breakdown['plate_date'] = opex_breakdown['mov_plate'].astype(str)+'_'+opex_breakdown['mov_movement_date'].astype(str)\n",
    "    opex_breakdown['days_since_last_movement'] = opex_breakdown.groupby('mov_plate').mov_movement_date.diff().dt.days\n",
    "    opex_breakdown['days_since_last_maintenance'] = opex_breakdown[opex_breakdown.mov_movement_type == 'SCHEDULED'].groupby('mov_plate').mov_movement_date.diff().dt.days\n",
    "    opex_breakdown['days_since_last_tires'] = opex_breakdown[opex_breakdown.mov_movement_type == 'TIRES'].groupby('mov_plate').mov_movement_date.diff().dt.days\n",
    "    opex_breakdown.days_since_last_movement = opex_breakdown.days_since_last_movement.fillna(-1)\n",
    "    opex_breakdown.days_since_last_maintenance = opex_breakdown.days_since_last_maintenance.fillna(-1)\n",
    "    opex_breakdown.days_since_last_tires = opex_breakdown.days_since_last_tires.fillna(-1)\n",
    "\n",
    "    # Add buckets for maintenance and tires\n",
    "    opex_breakdown['bucket_last_maintenance'] = opex_breakdown['days_since_last_maintenance'].apply(lambda x: days_bins(x))\n",
    "    opex_breakdown['bucket_last_tires'] = opex_breakdown['days_since_last_tires'].apply(lambda x: days_bins(x))\n",
    "    \n",
    "    \n",
    "    # Append static movement information\n",
    "    opex_breakdown['mov_movement_description']= opex_breakdown.mov_movement_description.apply(lambda x: str(x).replace('“','').replace('”','').replace('–',''))\n",
    "    opex_breakdown['via_brand'] = opex_breakdown['mov_plate'].map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_brand)))\n",
    "    opex_breakdown['via_classification'] = opex_breakdown['mov_plate'].map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_classification)))\n",
    "    opex_breakdown['via_category'] = opex_breakdown['mov_plate'].map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_category)))\n",
    "    opex_breakdown['via_fuel'] = opex_breakdown['mov_plate'].map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_fuel))).fillna('GASÓLEO')\n",
    "    opex_breakdown['via_attribution'] = opex_breakdown['mov_plate'].map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_attribution)))\n",
    "    opex_breakdown['via_city'] = opex_breakdown['mov_plate'].map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_city)))\n",
    "    opex_breakdown['eur_liter'] = (opex_breakdown['mov_total_net_price'] / opex_breakdown['mov_quantity']).fillna(0)\n",
    "    \n",
    "    # Collapse certain movement types to have a reduced movement type\n",
    "    opex_breakdown.loc[opex_breakdown.mov_movement_type == 'MULTA', 'mov_movement_type'] = 'OUTROS CUSTOS'\n",
    "    reduced_type_dict = dict(zip(opex_breakdown.mov_movement_type.unique(),opex_breakdown.mov_movement_type.unique()))\n",
    "    reduced_type_dict['NO SCHEDULED'] = 'MAINTENANCE'\n",
    "    reduced_type_dict['SCHEDULED'] =  'MAINTENANCE'\n",
    "    reduced_type_dict['TIRES'] = 'MAINTENANCE'\n",
    "    opex_breakdown['reduced_mov_type'] = opex_breakdown.mov_movement_type.map(reduced_type_dict)\n",
    "    \n",
    "    # Add moment of day variables\n",
    "    opex_breakdown['moment_of_day'] = opex_breakdown.mov_movement_time.apply(lambda x: moment_of_day(str(x)[:2]))\n",
    "    dictionary_weekday = {0: '1. Segunda-feira', 1: '2. Terça-feira', 2: '3. Quarta-feira', 3: '4. Quinta-feira', 4: '5. Sexta-feira',\n",
    "                             5: '6. Sábado', 6: '7. Domingo'}\n",
    "    opex_breakdown.mov_movement_date = pd.to_datetime(opex_breakdown.mov_movement_date)\n",
    "    opex_breakdown['weekday'] = opex_breakdown.mov_movement_date.apply(lambda x: dictionary_weekday[x.weekday()])\n",
    "\n",
    "\n",
    "    # ADD DATA OF EUR / KM / QUARTER\n",
    "    opex_breakdown['plate_quarter'] = (opex_breakdown['mov_plate'].astype(str)+'_'+\n",
    "                                       pd.to_datetime(opex_breakdown.mov_movement_date).apply(lambda x: x.quarter).astype(str))\n",
    "    opex_breakdown['km_in_quarter'] = opex_breakdown['plate_quarter'].map(\n",
    "        opex_breakdown.groupby('plate_quarter').mov_kms.apply(lambda x: max(x)-min(x)))\n",
    "    opex_breakdown['km_in_quarter'] = opex_breakdown['km_in_quarter'].fillna(1)\n",
    "    ncars = opex_breakdown.mov_plate.nunique()\n",
    "    opex_breakdown['eur_km_quarter'] = (opex_breakdown['mov_total_net_price'] / opex_breakdown['km_in_quarter']) / ncars\n",
    "    \n",
    "    \n",
    "    # Select columns to stick with\n",
    "    opex_cols = ['mov_plate', 'mov_movement_date', 'mov_movement_time','mov_movement_type','mov_kms','mov_quantity','mov_total_net_price','mov_supplier','mov_owner_company',\n",
    "                 'mov_movement_description','mov_accident_location','mov_exit','mov_cost_center','mov_category_of_vehicle','mov_status','trimester','is_last_period',\n",
    "                 'plate_date','days_since_last_movement','days_since_last_maintenance','days_since_last_tires','bucket_last_maintenance','bucket_last_tires',\n",
    "                 'via_brand','via_classification','via_category','via_fuel','via_attribution','via_city','eur_liter','reduced_mov_type','moment_of_day','weekday',\n",
    "                 'plate_quarter','km_in_quarter','eur_km_quarter']\n",
    "    \n",
    "    opex_breakdown = opex_breakdown[opex_cols]\n",
    "    \n",
    "    return opex_breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "159b19ab-11b1-445c-aa44-6261f0c13132",
     "showTitle": true,
     "title": "4.1 Portagens times"
    }
   },
   "outputs": [],
   "source": [
    "def portagens_times_table(movimentos):\n",
    "  '''This auxiliary function is a temporary solution for the lack of an adecuate time record of the movements. \n",
    "  It returns a table containing licence plate, location, entry and exit time of the toll even tas well as the best estimate for the time difference under the name diff'''\n",
    "  \n",
    "  # Select reduced group of variables\n",
    "  portagens_time = movimentos[['mov_plate', 'mov_movement_date','mov_movement_description', 'mov_exit', 'mov_movement_time', 'mov_exit_time' ]]\n",
    "  \n",
    "  # Define time difference between entry and exit to the portagen in minutes\n",
    "  entry = pd.to_datetime(portagens_time['mov_movement_date'].astype(str) + ' '+ portagens_time['mov_movement_time'].astype(str), errors='coerce')\n",
    "  exit = pd.to_datetime(portagens_time['mov_movement_date'].astype(str) + ' '+ portagens_time['mov_exit_time'].astype(str), errors='coerce')\n",
    "  portagens_time['diff'] = (exit-entry).dt.seconds / 60\n",
    "  \n",
    "  # Restrict the returning table to Portagens and include auxiliary for the visualization fields\n",
    "  portagens = portagens_time[movimentos.mov_movement_type == 'PORTAGEM']\n",
    "  portagens['mov_exit'] = portagens['mov_exit'].apply(lambda x: x.replace(', Portugal', ''))\n",
    "  portagens['entry_exit'] = 'De ' + portagens['mov_movement_description'] + ' para ' + portagens['mov_exit']\n",
    "\n",
    "  return portagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5678f137-5332-4c7d-b8f1-0d8455c75ff1",
     "showTitle": true,
     "title": "5. Cost calculator"
    }
   },
   "outputs": [],
   "source": [
    "def compute_costcalculator_table(clean_viaturas, clean_movimentos):\n",
    "  \n",
    "    '''Auxiliary function that given viaturas master table and movimentos master table returns the fatigue table. A table containing cost per KMs of various operational\n",
    "    activities'''\n",
    "    \n",
    "    print('5. Creating cost calculator table :::', time.ctime())\n",
    "    \n",
    "    # Select only the last snapshot operative vehicles from Servicio, Ligeiros and Combustível and a handful of variables for the cost calculator\n",
    "    fatigue = clean_viaturas[clean_viaturas['snapshot_date'] == clean_viaturas['snapshot_date'].max()]\n",
    "    fatigue = fatigue[fatigue.via_status.isin(['IMOB. POR ACIDENTE','OPERACIONAL'])]\n",
    "    fatigue_cols = ['via_plate', 'via_status','via_category', 'via_company','via_classification', 'via_brand', 'via_model',\n",
    "                    'via_fuel','via_attribution', 'via_total_kms','via_date_of_registration', 'via_cc_voltage', 'via_gross_weight', 'years_old']\n",
    "    fatigue = fatigue[fatigue_cols]\n",
    "    fatigue = fatigue[(fatigue.via_attribution == 'Viaturas de Serviço') & (fatigue.via_category == 'LIGEIRO') & (fatigue.via_fuel == 'Combustão')]\n",
    "    \n",
    "    # Look only at one year ago worth of movements to estimate the expense by KMs driven\n",
    "    clean_movimentos = clean_movimentos[clean_movimentos.mov_movement_date >= clean_movimentos.mov_movement_date.max() - pd.Timedelta('365 days')]\n",
    "    \n",
    "    # Assign the done KMs variable based on the corrected result of a regression of the liters consumed, the voltage and the gross weight of the vehicle\n",
    "    fatigue['liters'] = fatigue.via_plate.map(clean_movimentos[clean_movimentos.mov_movement_type == 'ABASTECIMENTO'\n",
    "                                                                ].groupby('mov_plate').mov_quantity.sum())\n",
    "    fatigue['done_kms'] = fatigue['liters'] * (2.14111935e+01 -  2.15275095e-04 * fatigue['via_cc_voltage'] - 4.03502335e-03 * fatigue['via_gross_weight'])\n",
    "    fatigue.loc[(fatigue.done_kms<=0), 'done_kms'] = fatigue.liters * 13\n",
    "                                                  \n",
    "    number_repairs = clean_movimentos[clean_movimentos.mov_movement_type.isin(['NO SCHEDULED','SCHEDULED','TIRES'])].groupby('mov_plate').mov_quantity.sum()\n",
    "    fatigue['number_repairs'] = fatigue.via_plate.map(number_repairs)\n",
    "    \n",
    "    \n",
    "    # Add cost per 1000Km indicators from different activities (maintenance, refuelling, insurance, tolls)\n",
    "    cost_maintenance = clean_movimentos[clean_movimentos.mov_movement_type.isin(['NO SCHEDULED','SCHEDULED','TIRES'])].groupby('mov_plate').mov_total_net_price.sum()\n",
    "    fatigue['cost_km_maintenance'] = fatigue.via_plate.map(cost_maintenance) / fatigue['done_kms']*1000\n",
    "\n",
    "    cost_abastecimento = clean_movimentos[clean_movimentos.mov_movement_type=='ABASTECIMENTO'].groupby('mov_plate').mov_total_net_price.sum()\n",
    "    fatigue['cost_km_abastecimento'] = fatigue.via_plate.map(cost_abastecimento) / fatigue['done_kms'] * 1000\n",
    "\n",
    "    cost_seguros = clean_movimentos[clean_movimentos.mov_movement_type=='SEGUROS'].groupby('mov_plate').mov_total_net_price.sum()\n",
    "    fatigue['cost_km_seguros'] = fatigue.via_plate.map(cost_seguros) / fatigue['done_kms']* 1000\n",
    "\n",
    "    cost_portagem = clean_movimentos[clean_movimentos.mov_movement_type=='PORTAGEM'].groupby('mov_plate').mov_total_net_price.sum()\n",
    "    fatigue['cost_km_portagem'] = fatigue.via_plate.map(cost_portagem) / fatigue['done_kms']* 1000\n",
    "\n",
    "    total_cost = clean_movimentos.groupby('mov_plate').mov_total_net_price.sum()\n",
    "    fatigue['cost_km_total'] = fatigue.via_plate.map(total_cost) / fatigue['done_kms']* 1000\n",
    "\n",
    "    fatigue.fillna(0, inplace = True)\n",
    "    fatigue.replace(np.inf, 0, inplace = True)\n",
    "\n",
    "    # Add buckets of age, KM done and number of repairs for the visualization\n",
    "    fatigue['km_bucket'] = fatigue.via_total_kms.apply(lambda x: bins_kms2(x))\n",
    "    fatigue['years_bucket'] = fatigue.years_old.apply(lambda x: bins_years2(x))\n",
    "    fatigue['repairs_bucket'] = fatigue.number_repairs.apply(lambda x: bins_repairs2(x))\n",
    "    \n",
    "    # Select columns to stick with\n",
    "    fatigue_cols = ['via_plate','via_status','via_category','via_company','via_classification','via_brand','via_model','via_fuel','via_attribution',\n",
    "                    'via_total_kms','via_date_of_registration','done_kms','years_old','number_repairs','cost_km_maintenance','cost_km_abastecimento','cost_km_seguros',\n",
    "                    'cost_km_portagem','cost_km_total','km_bucket','years_bucket','repairs_bucket']\n",
    "    fatigue = fatigue[fatigue_cols]\n",
    "    \n",
    "    return fatigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b15132e-ff23-42ca-9df2-36b90cc260b7",
     "showTitle": true,
     "title": "6. Electrification level"
    }
   },
   "outputs": [],
   "source": [
    "def electrification_table(clean_viaturas):\n",
    "  '''Auxiliary function to create the table that tracks the progress of the fleet electrification against the plan'''\n",
    "  \n",
    "  print('6. Creating electrification table :::', time.ctime())\n",
    "  \n",
    "  # Select operative vehicles and add electric flag to later compute the percentages\n",
    "  fleet_status = clean_viaturas[clean_viaturas.via_status.isin(['IMOB. POR ACIDENTE','OPERACIONAL'])]\n",
    "  fleet_status['is_electric'] = (fleet_status.via_fuel == 'Elétricos e Plug-Ins').astype(float)\n",
    "  \n",
    "  # Define the elect table that will contain the year, plan, actual and ratio of success in the electrification plan\n",
    "  elect = pd.DataFrame({'year': [2018,2019,2020,2021,2022,2023,2024,2025, 2026, 2027, 2028,2029,2030],\n",
    "                        'plan': [11,12,16,22,30,35,43,51,63,70,78, 90,100]})\n",
    "  dict_electrification = dict(zip(elect.year,\n",
    "                                  [fleet_status[(fleet_status.via_year == c) & \n",
    "                                                (fleet_status.via_month == fleet_status[fleet_status.via_year == c].via_month.max())\n",
    "                                               ].is_electric.mean()*100 for c in elect.year]))\n",
    "  elect['actual'] = elect['year'].map(dict_electrification)\n",
    "  elect['ratio'] = elect['actual']/elect['plan']*100\n",
    "  \n",
    "  # Select columns to stick with\n",
    "  elect_cols = ['plan', 'year', 'actual', 'ratio']\n",
    "  elect = elect[elect_cols]\n",
    "  return elect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1da08300-a2eb-4f7d-8511-0e8ef18eab03",
     "showTitle": true,
     "title": "7. Electrification scenarios"
    }
   },
   "outputs": [],
   "source": [
    "def electrification_scenarios(clean_viaturas):\n",
    "    ''' Auxiliary function to generate the electrification scenarios. Given:\n",
    "      - # of KM done by electric cars\n",
    "      - % of electric vehicles in the fleet\n",
    "      - % of yearly fleet increase\n",
    "    computes the CO2 saved taking as an assumption that on average 50g of CO2 are not emitted in contrast with typical combustão vehicles'''\n",
    "    \n",
    "    print('7. Creating electrification scenarios :::', time.ctime())\n",
    "    \n",
    "    # Select operative viaturas from the last snapshot\n",
    "    last_snapshot = clean_viaturas[clean_viaturas.via_status.isin(['IMOB. POR ACIDENTE','OPERACIONAL'])]\n",
    "    last_snapshot = last_snapshot[last_snapshot['snapshot_date'] == last_snapshot['snapshot_date'].max()]\n",
    "    current_fleet = last_snapshot.via_plate.nunique()\n",
    "    \n",
    "    # Run scenarios with predefined possible inputs for the different variables\n",
    "    elec_scenarios = pd.DataFrame()\n",
    "    for year in [2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030]:\n",
    "        for km_car in [5000,7500,10000,1250,15000,17500,20000,22500,25000]:\n",
    "            for perc_elec in [5,10,15,20,25,30,35,40,45,50,55,60]:\n",
    "                for fleet_increase in [-20,-15,-10,-5,0,5,10,15,20]:\n",
    "                    to_append = pd.DataFrame({'year': [year],\n",
    "                                              'electric_km': [km_car],\n",
    "                                              'perc_elect_fleet': [perc_elec],\n",
    "                                              'perc_inc_fleet': [fleet_increase],\n",
    "                                              'number_elec_cars': [current_fleet*((1+fleet_increase/100)**(year-2019))*perc_elec/100],\n",
    "                                              'number_elec_kms': [current_fleet*((1+fleet_increase/100)**(year-2019))*perc_elec/100*km_car],\n",
    "                                              'co2_saved': [current_fleet*((1+fleet_increase/100)**(year-2019))*perc_elec/100*km_car*0.05]})\n",
    "                    elec_scenarios = pd.concat([elec_scenarios, to_append])\n",
    "    \n",
    "    # Select columns to stick with\n",
    "    elec_scenarios_cols = ['co2_saved', 'electric_km', 'number_elec_cars', 'number_elec_kms', 'perc_elect_fleet', 'perc_inc_fleet', 'year']\n",
    "    elec_scenarios = elec_scenarios[elec_scenarios_cols]\n",
    "    return elec_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37aba592-a71b-472c-8ec6-0a1e283308e2",
     "showTitle": true,
     "title": "8. Utilization"
    }
   },
   "outputs": [],
   "source": [
    "def utilization_table(movimentos, viaturas):\n",
    "  \n",
    "  '''Auxiliary table to generate the utilization analysis for the current fleet '''\n",
    "  \n",
    "  print('8. Creating Utilization table :::', time.ctime())\n",
    "  \n",
    "  clean_movimentos = movimentos.copy()\n",
    "  clean_movimentos['year_quarter'] = clean_movimentos.mov_movement_date.apply(lambda x: x.year).astype(str)+'_'+clean_movimentos.mov_movement_date.apply(lambda x: x.quarter).astype(str)\n",
    "  clean_movimentos['date_quarter'] = clean_movimentos['year_quarter'].map(clean_movimentos.groupby('year_quarter').mov_movement_date.min()) + pd.offsets.MonthEnd(3)\n",
    "  clean_movimentos['key'] = clean_movimentos['date_quarter'].astype(str) + '_' + clean_movimentos['mov_plate']\n",
    "  \n",
    "  \n",
    "  # Subset movimentos to stick with Servicio, Ligeros, Combustion and operational\n",
    "  clean_movimentos['attribution'] = clean_movimentos['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_attribution)))\n",
    "  clean_movimentos['category'] = clean_movimentos['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_category)))\n",
    "  clean_movimentos['fuel'] = clean_movimentos['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_fuel)))\n",
    "  clean_movimentos = clean_movimentos[(clean_movimentos.attribution == 'Viaturas de Serviço') & \n",
    "                                      (clean_movimentos.category == 'LIGEIRO') & \n",
    "                                      (clean_movimentos.fuel == 'Combustão') & \n",
    "                                      (clean_movimentos.mov_category_of_vehicle.isin(['OPERACIONAL','IMOB. POR ACIDENTE']))]\n",
    "  \n",
    "  # Create utilization table based on abastecimentos\n",
    "  utilization = clean_movimentos[clean_movimentos.mov_movement_type == 'ABASTECIMENTO'].groupby(['date_quarter', 'mov_plate'])['mov_quantity'].sum().reset_index()\n",
    "  utilization['is_last_period'] = utilization['date_quarter'] == utilization['date_quarter'].max()\n",
    "  utilization['trimester'] = utilization['date_quarter'].apply(lambda x: add_trimester(x))\n",
    "  \n",
    "  # Add predicted KM as a regression of voltage, liters and gross weight corrected for extreme values\n",
    "  utilization['voltage_liters'] = utilization['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_cc_voltage))) * utilization.mov_quantity\n",
    "  utilization['gross_weight_liters'] = utilization['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_gross_weight))) * utilization.mov_quantity\n",
    "  utilization['predicted_kms'] = utilization['mov_quantity'] * 2.14111935e+01 - 2.15275095e-04*utilization['voltage_liters'] - 4.03502335e-03*utilization['gross_weight_liters']\n",
    "  utilization.loc[(utilization.predicted_kms<=0), 'predicted_kms'] = utilization.mov_quantity * 13\n",
    "  \n",
    "  \n",
    "  # Add utilization KPIs like age, number of repairs and indicators to filter\n",
    "  utilization['city'] = utilization['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_city)))\n",
    "  utilization['date_registration'] = utilization['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_date_of_registration)))\n",
    "  utilization['years_old'] = (utilization['date_quarter'] - pd.to_datetime(utilization.date_registration)).dt.days/365\n",
    "  utilization['owner_company'] = utilization['mov_plate'].map(dict(zip(movimentos.mov_plate, movimentos.mov_owner_company)))\n",
    "  utilization['cost_center'] = utilization['mov_plate'].map(dict(zip(movimentos.mov_plate, movimentos.mov_cost_center)))\n",
    "  utilization['category'] = utilization['mov_plate'].map(dict(zip(viaturas.via_plate, viaturas.via_category)))\n",
    "  utilization['key'] = utilization['date_quarter'].astype(str)+'_'+utilization['mov_plate']\n",
    "  utilization['n_repairs'] = utilization['key'].map(clean_movimentos[clean_movimentos.mov_movement_type.isin(['SCHEDULED', 'NO SCHEDULED', 'TIRES'])].groupby('key').size()).fillna(0)\n",
    "  \n",
    "  \n",
    "  # Add bins of the KM and the age for the barchart\n",
    "  utilization['bins_km'] = utilization.predicted_kms.apply(lambda x: bins_kms3(x))\n",
    "  utilization['bins_repairs'] = utilization.n_repairs.apply(lambda x: bins_repairs3(x))\n",
    "  \n",
    "  # Select columns to stick with\n",
    "  utilization_cols = ['date_quarter','mov_plate','mov_quantity','is_last_period','trimester','voltage_liters',\n",
    "                      'gross_weight_liters','predicted_kms','city','date_registration','years_old','owner_company',\n",
    "                      'cost_center','category','key','n_repairs','bins_km','bins_repairs']\n",
    "  utilization = utilization[utilization_cols]\n",
    "  \n",
    "  return utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a380958b-b013-4208-b5d6-c26ed08b748e",
     "showTitle": true,
     "title": "9. Replacement forecast"
    }
   },
   "outputs": [],
   "source": [
    "def replacement_forecast(clean_viaturas, clean_movimentos):\n",
    "    '''Auxiliary function that creates a forecast of the vehicles that will be obsolete in terms of age / Kms according to company policy in the upcoming years'''\n",
    "    \n",
    "    print('9. Creating Replacement forecast table :::', time.ctime())\n",
    "    \n",
    "    # Select operative vehicles in the latest snapshot\n",
    "    replacement_projections = clean_viaturas[clean_viaturas.via_status.isin(['IMOB. POR ACIDENTE','OPERACIONAL'])]\n",
    "    replacement_projections = replacement_projections[replacement_projections['snapshot_date'] == replacement_projections['snapshot_date'].max()]\n",
    "    \n",
    "    # Select some columns and define the KM per year per vehicle\n",
    "    replacement_projections['company'] = replacement_projections['via_company']\n",
    "    replacement_projections = replacement_projections[['via_plate', 'via_brand', 'via_attribution', 'via_category',\n",
    "                                                      'via_city', 'company', 'via_fuel','via_total_kms', 'years_old']]\n",
    "    replacement_projections['avg_km_per_year'] = replacement_projections['via_total_kms'] / replacement_projections['years_old'] \n",
    "    \n",
    "    # Add months ahead variable to later compute the replacement forecast\n",
    "    months_ahead = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    all_replacement_projections = pd.DataFrame()\n",
    "    for m in months_ahead:\n",
    "        temp = replacement_projections.copy()\n",
    "        temp['months_ahead'] = m\n",
    "        all_replacement_projections = pd.concat([all_replacement_projections, temp])\n",
    "    all_replacement_projections.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # Define the kms and years each given vehicle will have at m months ahead of time\n",
    "    all_replacement_projections['kms_ahead'] = (all_replacement_projections['via_total_kms']+\n",
    "                                                all_replacement_projections['months_ahead']*all_replacement_projections['avg_km_per_year']/12)\n",
    "    all_replacement_projections['years_ahead'] = (all_replacement_projections['years_old']+\n",
    "                                                all_replacement_projections['months_ahead']/12)\n",
    "    \n",
    "    # Default limits for vehicle replacement\n",
    "    all_replacement_projections['above_km'] = (all_replacement_projections['kms_ahead']>250000).astype(float)\n",
    "    all_replacement_projections['above_years'] = (all_replacement_projections['years_ahead']>8).astype(float)\n",
    "    \n",
    "    # Limits for servicio\n",
    "    all_replacement_projections.loc[(all_replacement_projections.via_attribution == 'SERVIÇO') & \n",
    "                                    (all_replacement_projections.via_fuel.isin(['GASÓLEO', 'GASOLINA'])), 'above_km'] = (all_replacement_projections['kms_ahead']>200000).astype(float)\n",
    "    all_replacement_projections.loc[(all_replacement_projections.via_attribution == 'SERVIÇO') & \n",
    "                                    (all_replacement_projections.via_fuel.isin(['GASÓLEO', 'GASOLINA'])), 'above_years'] = (all_replacement_projections['years_ahead']>8).astype(float)\n",
    "    \n",
    "    all_replacement_projections.loc[(all_replacement_projections.via_attribution == 'SERVIÇO') & \n",
    "                                    (all_replacement_projections.via_fuel.isin(['ENERGIA ELÉCTRICA'])), 'above_km'] = (all_replacement_projections['kms_ahead']> 160000).astype(float)\n",
    "    \n",
    "    # Limits for VUP\n",
    "    all_replacement_projections.loc[(all_replacement_projections.via_attribution.isin(['VUP', 'VUP/CA'])) & \n",
    "                                    (all_replacement_projections.via_fuel.isin(['ENERGIA ELÉCTRICA', 'PLUG-IN GASOLINA'])), \n",
    "                                    'above_km'] = (all_replacement_projections['kms_ahead']>150000).astype(float)\n",
    "    all_replacement_projections.loc[(all_replacement_projections.via_attribution.isin(['VUP', 'VUP/CA'])) & \n",
    "                                    (all_replacement_projections.via_fuel.isin(['ENERGIA ELÉCTRICA', 'PLUG-IN GASOLINA'])), \n",
    "                                    'above_years'] = (all_replacement_projections['years_ahead']>4).astype(float)\n",
    "    \n",
    "    \n",
    "    all_replacement_projections.loc[(all_replacement_projections.via_attribution.isin(['VUP', 'VUP/CA'])) & \n",
    "                                    (all_replacement_projections.via_fuel.isin(['GASÓLEO', 'GASOLINA', 'HÍBRIDO GASOLINA', 'HÍBRIDO GASÓLEO'])), \n",
    "                                    'above_km'] = (all_replacement_projections['kms_ahead']>150000).astype(float)\n",
    "    all_replacement_projections.loc[(all_replacement_projections.via_attribution.isin(['VUP', 'VUP/CA'])) & \n",
    "                                    (all_replacement_projections.via_fuel.isin(['GASÓLEO', 'GASOLINA', 'HÍBRIDO GASOLINA', 'HÍBRIDO GASÓLEO'])), \n",
    "                                    'above_years'] = (all_replacement_projections['years_ahead']>5).astype(float)\n",
    "    \n",
    "    # Select columns to stick with\n",
    "    replacement_cols = ['via_plate','via_brand','via_attribution','via_category','via_city','company','via_fuel','via_total_kms','years_old',\n",
    "                        'avg_km_per_year', 'months_ahead','kms_ahead','years_ahead','above_km','above_years']\n",
    "    all_replacement_projections = all_replacement_projections[replacement_cols]\n",
    "\n",
    "    return all_replacement_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b15e26e-f47f-4f24-adb0-35ea6dd376fe",
     "showTitle": true,
     "title": "10. Financial scenarios"
    }
   },
   "outputs": [],
   "source": [
    "def financial_scenarios(clean_viaturas, clean_movimentos):\n",
    "  \n",
    "    print('10. Creating financial scenarios :::', time.ctime())\n",
    "    \n",
    "    fleet_status = clean_viaturas[clean_viaturas.via_status.isin(['IMOB. POR ACIDENTE','OPERACIONAL'])]\n",
    "    fleet_status = fleet_status[fleet_status['snapshot_date'] == fleet_status['snapshot_date'].max()]\n",
    "    current_operative = fleet_status.copy()\n",
    "\n",
    "    clean_movimentos = clean_movimentos[clean_movimentos.mov_plate.isin(current_operative.via_plate)]\n",
    "    clean_movimentos = clean_movimentos[clean_movimentos.mov_movement_date >= pd.Timestamp.today() - pd.Timedelta('365 days')]\n",
    "\n",
    "    current_operative['min_kms'] = current_operative.via_plate.map(\n",
    "        clean_movimentos[clean_movimentos.mov_kms.fillna(0) != 0].groupby('mov_plate').mov_kms.min())\n",
    "    current_operative['max_kms'] = current_operative.via_plate.map(\n",
    "        clean_movimentos[clean_movimentos.mov_kms.fillna(0) != 0].groupby('mov_plate').mov_kms.max())\n",
    "    current_operative.loc[current_operative.max_kms > 500000, 'max_kms'] = 100000\n",
    "    current_operative['done_kms'] = current_operative['max_kms'] - current_operative['min_kms']\n",
    "    current_operative = current_operative[current_operative.done_kms.notnull()]\n",
    "    current_operative['is_electric'] = current_operative.via_fuel.isin(['ENERGIA ELÉCTRICA', 'PLUG-IN GASOLINA'])\n",
    "\n",
    "    # We define the fixed data for the scenarios\n",
    "    exp_scenarios = (fleet_status.groupby('via_company').size()).reset_index()\n",
    "    exp_scenarios.columns = ['via_company', 'number_cars']\n",
    "    exp_scenarios['share_in_fleet'] = exp_scenarios['number_cars'] / exp_scenarios['number_cars'].sum()\n",
    "    exp_scenarios['km_done'] = exp_scenarios.company.map(current_operative.groupby('via_company')['done_kms'].sum())\n",
    "    exp_scenarios['perc_electric'] = exp_scenarios['company'].map(current_operative.groupby('via_company')['is_electric'].mean())\n",
    "\n",
    "    # We append data by expense type\n",
    "    res = pd.DataFrame()\n",
    "    for t in clean_movimentos.mov_movement_type.unique():\n",
    "        temp = exp_scenarios.copy()\n",
    "        temp['expense_type'] = t\n",
    "        temp['eur_km'] = exp_scenarios.company.map(\n",
    "            clean_movimentos[clean_movimentos.mov_movement_type == t].groupby(\n",
    "                'mov_owner_company').mov_total_net_price.sum()).fillna(0) / exp_scenarios['km_done']\n",
    "        res = pd.concat([res, temp])\n",
    "    res = res.fillna(0).replace([np.inf,-np.inf],0).reset_index(drop = True)\n",
    "\n",
    "    # We generate the scenarios according to each and every input\n",
    "    cost_scenario = pd.DataFrame()\n",
    "    for serv_increase in [-10,-5,-2,0,2,5,10]:\n",
    "        for cars_dismissed in [200-c*40 for c in range(6)]:\n",
    "            for cars_purchased in [400-c*40 for c in range(11)]:\n",
    "                for perc_elect in [0,5,10,15,20,25,30]:\n",
    "                    for price_new_cars in [10000,11000,12000,13000,14000,15000]:\n",
    "                        temp = res.copy()\n",
    "                        temp['serv_increase'] = serv_increase\n",
    "                        temp['cars_dismissed'] = cars_dismissed\n",
    "                        temp['cars_purchased'] = cars_purchased\n",
    "                        temp['perc_elect'] = perc_elect\n",
    "                        temp['price_new_cars'] = price_new_cars\n",
    "                        temp['scenario_ncars'] = temp['number_cars'] + cars_purchased - cars_dismissed\n",
    "                        temp['scenario_km_per_car'] = temp['km_done'] * (serv_increase/100+1) / temp.scenario_ncars\n",
    "                        temp['scenario_eur'] = temp['eur_km']*temp['scenario_ncars']*temp['scenario_km_per_car']\n",
    "                        temp.loc[temp.expense_type == 'ABASTECIMENTO','scenario_eur'] = temp['scenario_eur']-temp['scenario_eur']*perc_elect/100/2\n",
    "                        temp['capex_expense'] = cars_purchased * price_new_cars\n",
    "                        temp['capex_income'] = cars_dismissed * 3000\n",
    "                        temp['capex_balance'] = temp['capex_expense'] - temp['capex_income']\n",
    "                        temp['delta_capex'] = (cars_dismissed - cars_purchased) * price_new_cars\n",
    "                        cost_scenario = pd.concat([cost_scenario, temp])\n",
    "    cost_scenario.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return cost_scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48db77f6-6bc6-4671-abe0-93aa53074c0f",
     "showTitle": true,
     "title": "11. Matrícula details"
    }
   },
   "outputs": [],
   "source": [
    "def matricula_table(viaturas, clean_movimentos):\n",
    "  \n",
    "  print('11. Creating Matrícula details table :::', time.ctime())\n",
    "  \n",
    "  clean_viaturas = viaturas.sort_values('snapshot_date', ascending = False).drop_duplicates('via_plate')\n",
    "  matricula = pd.DataFrame({'via_plate': clean_viaturas.via_plate.unique()})\n",
    "  \n",
    "  # Static vehicle information\n",
    "  matricula['brand'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_brand)))\n",
    "  matricula['model'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_model)))\n",
    "  matricula['category'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_category)))\n",
    "  matricula['classification'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_classification)))\n",
    "  matricula['attribution'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_attribution)))\n",
    "  matricula['via_co2_emissions'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_co2_emissions)))\n",
    "  matricula['fuel'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_fuel)))\n",
    "  matricula['city'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_city)))\n",
    "  matricula['date_of_registration'] = pd.to_datetime(matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_date_of_registration))))\n",
    "  matricula['acquisition_value'] = matricula.via_plate.map(clean_viaturas.groupby('via_plate').via_acquisition_value.max())\n",
    "  matricula['cost_center'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_cost_center)))\n",
    "  matricula['total_kms'] = matricula.via_plate.map(clean_viaturas.groupby('via_plate').via_total_kms.max())\n",
    "  matricula['owner_company'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_company)))\n",
    "  matricula['cc_voltage'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_cc_voltage)))\n",
    "  matricula['gross_weight'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_gross_weight)))\n",
    "  matricula['status'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.via_status)))\n",
    "  matricula['years_old'] = matricula.via_plate.map(dict(zip(clean_viaturas.via_plate, clean_viaturas.years_old)))\n",
    "  \n",
    "  # Usage stats\n",
    "  mov_cols = ['mov_plate', 'mov_movement_date', 'mov_total_net_price', 'mov_quantity', 'mov_movement_type']\n",
    "  matricula = pd.merge(matricula, \n",
    "                       clean_movimentos[mov_cols],\n",
    "                       left_on='via_plate',\n",
    "                       right_on='mov_plate',\n",
    "                       how='left')\n",
    "  matricula['trimester'] = matricula['mov_movement_date'].apply(lambda x: add_trimester(x))\n",
    "  \n",
    "  # Computing km driven using liters\n",
    "  mask = (matricula.mov_movement_type == \"ABASTECIMENTO\")\n",
    "  matricula['km_driven'] = 0\n",
    "  matricula.loc[mask, 'km_driven'] =  (2.14111935e+01* matricula['mov_quantity'] - \n",
    "                                      2.15275095e-04* matricula['mov_quantity'] * matricula['cc_voltage'] -\n",
    "                                      4.03502335e-03 *matricula['mov_quantity'] * matricula['gross_weight'])\n",
    "  matricula['category_classification'] = matricula['category'] + '_' + matricula['classification']\n",
    "  \n",
    "  return matricula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00f7530b-fbb0-4fc3-9c5f-829d7c64c2a8",
     "showTitle": true,
     "title": "12. Excel reports"
    }
   },
   "outputs": [],
   "source": [
    "def tables_excel(viaturas, movimentos):\n",
    "  print('12. Creating excel reports table :::', time.ctime())\n",
    "  currentviaturas = viaturas[viaturas.via_status.isin(['IMOB. POR ACIDENTE','OPERACIONAL'])]\n",
    "  currentviaturas['snapshot_date'] = pd.to_datetime(currentviaturas['via_year'].astype(str)+'-'+currentviaturas['via_month'].astype(str))\n",
    "  currentviaturas = currentviaturas[currentviaturas['snapshot_date'] == currentviaturas['snapshot_date'].max()]\n",
    "\n",
    "  currentviaturas['eur_spent'] = currentviaturas.via_plate.map(movimentos.groupby('mov_plate')['mov_total_net_price'].sum())\n",
    "\n",
    "  table1 = currentviaturas.groupby(['via_attribution', 'via_category']).eur_spent.agg(Veículos= 'count',Euros='sum').reset_index()\n",
    "  table1['Custo Unitário'] = table1['Euros'] / table1['Veículos']\n",
    "  \n",
    "  ###########################################################################\n",
    "  \n",
    "  def km_bins(x):\n",
    "    if (x == 0): return '1. 0 Kms'\n",
    "    if (x < 4500): return '2. 1-4500 Km'\n",
    "    if (x < 9000): return '3. 4501-9000 Km'\n",
    "    if (x < 13500): return '4. 9001-13500 Km'\n",
    "    if (x < 18000): return '5. 1501-18000 Km'\n",
    "    if (x >= 18000): return '6. >18000 Km'\n",
    "    return 'not'\n",
    "  table2 = currentviaturas['via_total_kms'].apply(lambda x: km_bins(x)).value_counts().reset_index().sort_values('index')\n",
    "  table2.columns = ['Km Percorridos', '#']\n",
    "  \n",
    "  ###########################################################################\n",
    "  \n",
    "  movimentos['is_last_period'] = (pd.to_datetime(movimentos['mov_movement_date']) >= pd.to_datetime(str(movimentos['mov_movement_date'].max().year)+'-01')).astype(float)\n",
    "  my_movimentos = movimentos[(movimentos.mov_plate.isin(currentviaturas.via_plate)) & (movimentos.is_last_period == True)]\n",
    "  currentviaturas['consumos'] = currentviaturas.via_plate.map(my_movimentos[my_movimentos.mov_movement_type == 'ABASTECIMENTO'].groupby('mov_plate').mov_quantity.sum()).fillna(0)\n",
    "  currentviaturas['absatecimento'] = currentviaturas.via_plate.map(my_movimentos[my_movimentos.mov_movement_type == 'ABASTECIMENTO'].groupby('mov_plate').mov_total_net_price.sum()).fillna(0)\n",
    "\n",
    "  my_movimentos['liters_cc'] = 2#my_movimentos['mov_quantity'] * my_movimentos.mov_plate.map(dict(zip(currentviaturas.via_plate, currentviaturas.via_cc_voltage)))\n",
    "  my_movimentos['liters_weight'] = 2#my_movimentos['mov_quantity'] * my_movimentos.mov_plate.map(dict(zip(currentviaturas.via_plate, currentviaturas.via_gross_weight)))\n",
    "\n",
    "\n",
    "  my_movimentos.loc[my_movimentos.mov_movement_type == 'ABASTECIMENTO', 'predicted_kms'] =  2#(19.4091301*my_movimentos.mov_quantity -\n",
    "                                                                                            # 2.37490333e-03* my_movimentos.liters_cc -\n",
    "                                                                                            # 2.08773361e-03*my_movimentos.liters_weight)\n",
    "  my_movimentos.predicted_kms.fillna(0, inplace = True)\n",
    "  currentviaturas['predicted_kms'] = currentviaturas.via_plate.map(my_movimentos[my_movimentos.mov_movement_type == 'ABASTECIMENTO'].groupby('mov_plate').predicted_kms.sum()).fillna(0)\n",
    "  \n",
    "  \n",
    "  \n",
    "  table3 = currentviaturas.groupby('via_fuel').size().reset_index()\n",
    "  table3.columns = ['Tipo de Combustível', 'Veículos']\n",
    "  table3['% Combustível'] = round(table3['Veículos'] / table3['Veículos'].sum()*100,2)\n",
    "  table3['KM'] = table3['Tipo de Combustível'].map(currentviaturas.groupby('via_fuel').predicted_kms.sum())\n",
    "  table3['Consumos'] = table3['Tipo de Combustível'].map(currentviaturas.groupby('via_fuel')['consumos'].sum())\n",
    "  table3['Abastecimentos'] = table3['Tipo de Combustível'].map(currentviaturas.groupby('via_fuel')['absatecimento'].sum())\n",
    "  table3['€/Consumo'] = table3['Abastecimentos'] / table3['Consumos']\n",
    "  table3['€/KM'] = table3['Abastecimentos'] / table3['KM']\n",
    "  \n",
    "  \n",
    "  ###########################################################################\n",
    "  \n",
    "  table4 = movimentos.copy()\n",
    "  table4['mov_movement_date'] = pd.to_datetime(table4['mov_movement_date'])\n",
    "  table4['is_last_period'] = (table4['mov_movement_date'] >= pd.to_datetime(str(table4['mov_movement_date'].max().year)+'-01')).astype(float)\n",
    "  table4 = table4[table4.is_last_period == True]\n",
    "  table4 = table4.groupby('mov_movement_type')['mov_total_net_price'].sum().reset_index()\n",
    "  table4.columns = ['Categoria custo', 'Valor']\n",
    "  table4['%'] = table4['Valor'] / table4['Valor'].sum()\n",
    "  \n",
    "  ###########################################################################\n",
    "  \n",
    "  \n",
    "  \n",
    "  return table1, table2, table3, table4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cd71b7b-7255-4457-b2a8-6a747daa0e9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "viaturas = load_viaturas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19f9b3b8-2a51-4649-98b5-f1cbb31946da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "viaturas = load_viaturas()\n",
    "movimentos = load_movimentos()\n",
    "balances = fleet_balances_table(viaturas, movimentos)\n",
    "capex = capex_table(balances, viaturas, movimentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6760884-883b-4197-a5f0-611d87889a8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_in_blob(capex, '/out/csv/03_capex_v7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f509415f-169e-4e25-a6e3-6a1fe087b32d",
     "showTitle": true,
     "title": "### MAIN ###"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  '''Function that triggers all of the previously displayed functionalities'''\n",
    "  viaturas = load_viaturas()\n",
    "  movimentos = load_movimentos()\n",
    "  cadastro = load_cadastro()\n",
    "  \n",
    "  filtering_slicer = filters_table(viaturas)\n",
    "  save_in_blob(filtering_slicer, '/out/csv/00_Filters_v10')\n",
    "  \n",
    "  fleet_status = fleet_status_table(movimentos, viaturas, cadastro)\n",
    "  save_in_blob(fleet_status, '/out/csv/01_Fleet_Status_v9')\n",
    "  \n",
    "  balances = fleet_balances_table(viaturas, movimentos)\n",
    "  save_in_blob(balances, '/out/csv/02_Fleet_Balances_v7')\n",
    "  \n",
    "  capex = capex_table(balances, viaturas, movimentos)\n",
    "  save_in_blob(capex, '/out/csv/03_capex_v7')\n",
    "  \n",
    "  opex_breakdown = opex_table(viaturas, movimentos)\n",
    "  save_in_blob(opex_breakdown, '/out/csv/04_Opex_v6')\n",
    "  \n",
    "  portagens = portagens_times_table(movimentos)\n",
    "  save_in_blob(portagens, '/out/csv/04_portagenstimes_v3')\n",
    "  \n",
    "  cost_calculator = compute_costcalculator_table(viaturas, movimentos)\n",
    "  save_in_blob( cost_calculator, '/out/csv/05_fatigue_v7')\n",
    "  \n",
    "  electrification = electrification_table(viaturas)\n",
    "  save_in_blob(electrification, '/out/csv/06_electrification_v2')\n",
    "  \n",
    "  electric_scenarios = electrification_scenarios(viaturas)\n",
    "  save_in_blob(electric_scenarios, '/out/csv/07_elec_scenarios_v1')\n",
    "  \n",
    "  utilization = utilization_table(movimentos, viaturas)\n",
    "  save_in_blob(utilization, '/out/csv/08_utilization_v9')\n",
    "  \n",
    "  car_replacements = replacement_forecast(viaturas, movimentos)\n",
    "  save_in_blob(car_replacements, '/out/csv/09_car_replacements_v6')\n",
    "  \n",
    "  #costs = financial_scenarios(viaturas, movimentos)\n",
    "  #save_in_blob(costs, '10_costs_v1')\n",
    "  \n",
    "  matricula = matricula_table(viaturas, movimentos)\n",
    "  save_in_blob(matricula, '/out/csv/11_matricula_details_v6')\n",
    "  \n",
    "  table1, table2, table3, table4 = tables_excel(viaturas, movimentos)\n",
    "  save_in_blob(table1, '/out/csv/12_exceltables1_v1')\n",
    "  save_in_blob(table2, '/out/csv/12_exceltables2_v1')\n",
    "  save_in_blob(table3, '/out/csv/12_exceltables3_v1')\n",
    "  save_in_blob(table4, '/out/csv/12_exceltables4_v1')\n",
    "  \n",
    "  return 'DONE!'\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab699cf9-d649-4ef0-ac03-e1c0fcd4d1bc",
     "showTitle": true,
     "title": "Run main"
    }
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5706f62-30a1-481c-bedd-19a28fd5e2e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clean_tables",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
