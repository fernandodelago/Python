#!/usr/bin/env python
# coding: utf-8

def remove_delta_table(var_db, var_nome_tabela, var_path):
  '''
  Função que deleta tabelas Delta do datalake Azure
  Entrada:
   var_db - nome do schema do datalake.
   var_nome_tabela - nome da tabela do datalake.
   var_path - caminho onde fica os dados da tabela Delta no datalake
  Retorno:
  rc_code
   |-> 0 - Tabela excluída com sucesso.
   |-> 1 - Tabela não encontrada. Confirme o database e o path informado se estão corretos.
   |-> 9 - Erro inesperado.
  ret_msg - mensagem de retorno de acordo com o rc_code.
  '''
  try:
    db_tabela = var_db + '.' + var_nome_tabela
    df_table = spark.sql('''show tables in {db} like "{tabela}" '''.format(db = var_db, tabela = var_nome_tabela))
    v_exist = str(df_table.count())
    
    if v_exist == '1':
      dbutils.fs.rm('{var_path_wrk}/{nome_tabela}'.format(var_path_wrk = var_path, nome_tabela = var_nome_tabela),True)
      spark.sql('DROP TABLE if exists {tabela}'.format(tabela = db_tabela))
      rc_code = 0
    else:
      rc_code = 1
  except:
    rc_code = 9
  finally:
    if rc_code == 0:
      ret_msg = 'Tabela excluída ' + db_tabela + ' com sucesso.'
    elif rc_code == 1:
      ret_msg = 'Tabela ' + db_tabela + ' não encontrada. Confirme o database e o path informado se estão corretos.'
    else:
      ret_msg = 'Ocorreu um erro inesperado.'
      
    print('# ' + ret_msg)
    return rc_code, ret_msg
print('# Função remove_delta_table() definida.')
print('# Para usar: remove_delta_table(var_db, var_nome_tabela, var_path)')
print('#')
